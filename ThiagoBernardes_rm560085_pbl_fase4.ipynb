{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "82f6f16f",
   "metadata": {},
   "source": [
    "## Projeto de Previsão do Rendimento da Safra\n",
    "Este notebook apresenta uma solução para o projeto, envolvendo:\n",
    "\n",
    "- Análise Exploratória de Dados (EDA)\n",
    "- Clusterização e Detecção de Outliers\n",
    "- Construção de Modelos Preditivos de Regressão\n",
    "- Avaliação dos Modelos\n",
    "\n",
    "A base de dados utilizada é a “crop_yield.csv”, que contém informações sobre:\n",
    "\n",
    "- Cultura\n",
    "- Precipitação (mm dia 1)\n",
    "- Umidade específica a 2 metros (g/kg)\n",
    "- Umidade relativa a 2 metros (%)\n",
    "- Temperatura a 2 metros (ºC)\n",
    "- Rendimento (ton/ha)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5585c59c",
   "metadata": {},
   "source": [
    "### 1. Introdução e Carregamento dos Dados\n",
    "Nesta seção, fazemos a leitura dos dados e apresentamos uma visão inicial do dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6268a327",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importando as bibliotecas necessárias\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Configuração de estilo para os gráficos\n",
    "sns.set(style=\"whitegrid\", palette=\"muted\", color_codes=True)\n",
    "\n",
    "# Carregando o dataset\n",
    "df = pd.read_csv(\"crop_yield.csv\")\n",
    "\n",
    "# Exibindo as primeiras linhas do dataset\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c53dfa4e",
   "metadata": {},
   "source": [
    "Comentários:\n",
    "\n",
    "- Verificamos as colunas disponíveis e uma amostra dos dados.\n",
    "- Identificamos a necessidade de tratamento de valores faltantes ou outliers."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ebe5e21",
   "metadata": {},
   "source": [
    "### 2. Análise Exploratória dos Dados (EDA)\n",
    "Esta etapa inclui a análise descritiva e visualização das variáveis para entender a distribuição dos dados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82aaf9ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Informações gerais sobre o dataset\n",
    "print(df.info())\n",
    "\n",
    "# Estatísticas descritivas\n",
    "print(df.describe())\n",
    "\n",
    "# Distribuição das variáveis numéricas\n",
    "df.hist(bins=20, figsize=(15, 10))\n",
    "plt.suptitle(\"Histograma das Variáveis\")\n",
    "plt.show()\n",
    "\n",
    "# Matriz de correlação para identificar relações entre as variáveis\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(df.corr(), annot=True, cmap=\"coolwarm\")\n",
    "plt.title(\"Matriz de Correlação\")\n",
    "plt.show()\n",
    "\n",
    "# Boxplots para identificar outliers em cada variável numérica\n",
    "plt.figure(figsize=(15, 6))\n",
    "for idx, col in enumerate(['Precipitação (mm dia 1)', 'Umidade específica a 2 metros (g/kg)', \n",
    "                           'Umidade relativa a 2 metros (%)', 'Temperatura a 2 metros (ºC)', 'Rendimento']):\n",
    "    plt.subplot(1, 5, idx+1)\n",
    "    sns.boxplot(y=df[col])\n",
    "    plt.title(col)\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1aaf9422",
   "metadata": {},
   "source": [
    "Comentários:\n",
    "\n",
    "- A análise descritiva e os gráficos ajudam a identificar padrões, possíveis correlações e outliers que podem influenciar os modelos."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f391a371",
   "metadata": {},
   "source": [
    "### 3. Clusterização e Detecção de Outliers\n",
    "Utilizaremos métodos de clusterização para identificar grupos de rendimentos e detectar outliers. Neste exemplo, aplicaremos o K-Means e o DBSCAN."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9eee14e",
   "metadata": {},
   "source": [
    "#### Preparação dos Dados para Clusterização"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0c64e14",
   "metadata": {},
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Selecionando apenas as variáveis numéricas para clusterização (exceto 'Cultura')\n",
    "features = df[['Precipitação (mm dia 1)', 'Umidade específica a 2 metros (g/kg)',\n",
    "               'Umidade relativa a 2 metros (%)', 'Temperatura a 2 metros (ºC)', 'Rendimento']]\n",
    "\n",
    "# Normalizando os dados\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(features)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0dc38b3",
   "metadata": {},
   "source": [
    "#### Aplicando o K-Means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8a38c8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "\n",
    "# Definindo o número de clusters (podemos usar o método do cotovelo para identificar K ideal)\n",
    "kmeans = KMeans(n_clusters=3, random_state=42)\n",
    "clusters_km = kmeans.fit_predict(X_scaled)\n",
    "\n",
    "# Adicionando os clusters ao dataframe original\n",
    "df['Cluster_KMeans'] = clusters_km\n",
    "\n",
    "# Visualizando os clusters em um gráfico de dispersão (utilizando duas dimensões, por exemplo, Rendimento e Temperatura)\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.scatterplot(x=df['Temperatura a 2 metros (ºC)'], y=df['Rendimento'], hue=df['Cluster_KMeans'], palette=\"viridis\")\n",
    "plt.title(\"Clusterização com K-Means\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbcb3ed2",
   "metadata": {},
   "source": [
    "#### Aplicando o DBSCAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c7e992c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import DBSCAN\n",
    "\n",
    "# Parâmetros do DBSCAN (epsilon e min_samples) podem ser ajustados conforme a densidade dos dados\n",
    "dbscan = DBSCAN(eps=0.8, min_samples=5)\n",
    "clusters_db = dbscan.fit_predict(X_scaled)\n",
    "\n",
    "# Adicionando os clusters do DBSCAN ao dataframe\n",
    "df['Cluster_DBSCAN'] = clusters_db\n",
    "\n",
    "# Visualizando os clusters DBSCAN\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.scatterplot(x=df['Temperatura a 2 metros (ºC)'], y=df['Rendimento'], hue=df['Cluster_DBSCAN'], palette=\"deep\")\n",
    "plt.title(\"Clusterização com DBSCAN (Outliers marcados como -1)\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6762cc7b",
   "metadata": {},
   "source": [
    "Comentários:\n",
    "\n",
    "- O K-Means divide os dados em grupos pré-definidos, enquanto o DBSCAN também identifica pontos considerados ruído (marcados como –1)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef62b912",
   "metadata": {},
   "source": [
    "### 4. Construção de Modelos Preditivos de Regressão\n",
    "Serão desenvolvidos cinco modelos preditivos utilizando algoritmos distintos. A seguir, um exemplo com:\n",
    "\n",
    "- Regressão Linear Simples / Múltipla\n",
    "- Árvore de Decisão\n",
    "- Random Forest\n",
    "- XGBoost\n",
    "- Regressão por Support Vector Regression (SVR)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92a88116",
   "metadata": {},
   "source": [
    "#### Preparação dos Dados para Regressão"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d4412a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Para predição, vamos utilizar todas as variáveis preditoras (exceto 'Cultura' e os indicadores de clusterização)\n",
    "X = df[['Precipitação (mm dia 1)', 'Umidade específica a 2 metros (g/kg)',\n",
    "        'Umidade relativa a 2 metros (%)', 'Temperatura a 2 metros (ºC)']]\n",
    "y = df['Rendimento']\n",
    "\n",
    "# Dividindo o dataset em treino (70%) e teste (30%)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "394cc1fa",
   "metadata": {},
   "source": [
    "#### Modelo 1: Regressão Linear"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11193c41",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "\n",
    "# Instanciando e treinando o modelo de regressão linear\n",
    "model_lr = LinearRegression()\n",
    "model_lr.fit(X_train, y_train)\n",
    "\n",
    "# Previsões\n",
    "y_pred_lr = model_lr.predict(X_test)\n",
    "\n",
    "# Avaliação\n",
    "mae_lr = mean_absolute_error(y_test, y_pred_lr)\n",
    "mse_lr = mean_squared_error(y_test, y_pred_lr)\n",
    "rmse_lr = np.sqrt(mse_lr)\n",
    "r2_lr = r2_score(y_test, y_pred_lr)\n",
    "\n",
    "print(\"Regressão Linear:\")\n",
    "print(f\"MAE: {mae_lr:.2f}, MSE: {mse_lr:.2f}, RMSE: {rmse_lr:.2f}, R²: {r2_lr:.2f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0ab2dd1",
   "metadata": {},
   "source": [
    "#### Modelo 2: Árvore de Decisão"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72fb1a35",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeRegressor\n",
    "\n",
    "model_dt = DecisionTreeRegressor(random_state=42)\n",
    "model_dt.fit(X_train, y_train)\n",
    "y_pred_dt = model_dt.predict(X_test)\n",
    "\n",
    "mae_dt = mean_absolute_error(y_test, y_pred_dt)\n",
    "mse_dt = mean_squared_error(y_test, y_pred_dt)\n",
    "rmse_dt = np.sqrt(mse_dt)\n",
    "r2_dt = r2_score(y_test, y_pred_dt)\n",
    "\n",
    "print(\"Árvore de Decisão:\")\n",
    "print(f\"MAE: {mae_dt:.2f}, MSE: {mse_dt:.2f}, RMSE: {rmse_dt:.2f}, R²: {r2_dt:.2f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84649784",
   "metadata": {},
   "source": [
    "#### Modelo 3: Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5e38f57",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "model_rf = RandomForestRegressor(n_estimators=100, random_state=42)\n",
    "model_rf.fit(X_train, y_train)\n",
    "y_pred_rf = model_rf.predict(X_test)\n",
    "\n",
    "mae_rf = mean_absolute_error(y_test, y_pred_rf)\n",
    "mse_rf = mean_squared_error(y_test, y_pred_rf)\n",
    "rmse_rf = np.sqrt(mse_rf)\n",
    "r2_rf = r2_score(y_test, y_pred_rf)\n",
    "\n",
    "print(\"Random Forest:\")\n",
    "print(f\"MAE: {mae_rf:.2f}, MSE: {mse_rf:.2f}, RMSE: {rmse_rf:.2f}, R²: {r2_rf:.2f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d153475",
   "metadata": {},
   "source": [
    "#### Modelo 4: XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5f4ffd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "\n",
    "model_xgb = xgb.XGBRegressor(objective='reg:squarederror', n_estimators=100, random_state=42)\n",
    "model_xgb.fit(X_train, y_train)\n",
    "y_pred_xgb = model_xgb.predict(X_test)\n",
    "\n",
    "mae_xgb = mean_absolute_error(y_test, y_pred_xgb)\n",
    "mse_xgb = mean_squared_error(y_test, y_pred_xgb)\n",
    "rmse_xgb = np.sqrt(mse_xgb)\n",
    "r2_xgb = r2_score(y_test, y_pred_xgb)\n",
    "\n",
    "print(\"XGBoost:\")\n",
    "print(f\"MAE: {mae_xgb:.2f}, MSE: {mse_xgb:.2f}, RMSE: {rmse_xgb:.2f}, R²: {r2_xgb:.2f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b885b52",
   "metadata": {},
   "source": [
    "#### Modelo 5: SVR (Support Vector Regression)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1e9b3c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVR\n",
    "\n",
    "model_svr = SVR(kernel='rbf', C=100, gamma=0.1, epsilon=.1)\n",
    "model_svr.fit(X_train, y_train)\n",
    "y_pred_svr = model_svr.predict(X_test)\n",
    "\n",
    "mae_svr = mean_absolute_error(y_test, y_pred_svr)\n",
    "mse_svr = mean_squared_error(y_test, y_pred_svr)\n",
    "rmse_svr = np.sqrt(mse_svr)\n",
    "r2_svr = r2_score(y_test, y_pred_svr)\n",
    "\n",
    "print(\"SVR:\")\n",
    "print(f\"MAE: {mae_svr:.2f}, MSE: {mse_svr:.2f}, RMSE: {rmse_svr:.2f}, R²: {r2_svr:.2f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e737492",
   "metadata": {},
   "source": [
    "Comentários:\n",
    "\n",
    "- Cada modelo é treinado e avaliado utilizando as métricas MAE, MSE, RMSE e R².\n",
    "- A comparação entre os modelos permitirá identificar qual abordagem se ajusta melhor à previsão do rendimento."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a56e679",
   "metadata": {},
   "source": [
    "### 5. Avaliação e Discussão dos Resultados\n",
    "Nesta seção, os resultados dos modelos são comparados. Por exemplo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60cda62a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Consolidando os resultados dos modelos em um DataFrame para comparação\n",
    "resultados = pd.DataFrame({\n",
    "    \"Modelo\": [\"Regressão Linear\", \"Árvore de Decisão\", \"Random Forest\", \"XGBoost\", \"SVR\"],\n",
    "    \"MAE\": [mae_lr, mae_dt, mae_rf, mae_xgb, mae_svr],\n",
    "    \"MSE\": [mse_lr, mse_dt, mse_rf, mse_xgb, mse_svr],\n",
    "    \"RMSE\": [rmse_lr, rmse_dt, rmse_rf, rmse_xgb, rmse_svr],\n",
    "    \"R²\": [r2_lr, r2_dt, r2_rf, r2_xgb, r2_svr]\n",
    "})\n",
    "resultados\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2caaeef",
   "metadata": {},
   "source": [
    "Discussão:\n",
    "\n",
    "- Analise os erros médios (MAE e RMSE) para identificar qual modelo apresenta previsões mais precisas.\n",
    "- Considere o valor do R² para entender o quão bem cada modelo explica a variabilidade dos dados.\n",
    "- Discuta possíveis razões para diferenças de desempenho e quais melhorias (como tuning de hiperparâmetros ou engenharia de features) podem ser implementadas."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa338b11",
   "metadata": {},
   "source": [
    "### 6. Conclusões e Limitações\n",
    "Conclusões:\n",
    "\n",
    "- Integração de Técnicas: O projeto combinou abordagens não supervisionadas (clusterização) e supervisionadas (regressão) para entender e prever o rendimento agrícola.\n",
    "- Resultados: Através dos modelos testados, foi possível identificar qual algoritmo teve melhor desempenho na previsão do rendimento, auxiliando na tomada de decisão para a gestão da produção.\n",
    "- Outliers e Padrões: A identificação dos clusters e outliers contribuiu para a compreensão dos fatores que afetam a produtividade.\n",
    "\n",
    "Limitações e Pontos de Melhoria:\n",
    "\n",
    "- Possíveis limitações na qualidade dos dados (ruídos, valores faltantes) que podem influenciar os modelos.\n",
    "- Necessidade de validação adicional com dados de outras safras ou de diferentes regiões para garantir a robustez dos modelos.\n",
    "- Ajustes finos nos hiperparâmetros e testes com outras técnicas de engenharia de features podem melhorar o desempenho preditivo."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
